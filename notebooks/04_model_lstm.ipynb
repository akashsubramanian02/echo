{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841f530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Akash Subramanian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d6c8f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not satisfied many bugs and issues</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazing quality and userfriendly interface</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terrible experience needs major improvements</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poor performance and not userfriendly</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not satisfied many bugs and issues</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   clean_review sentiment\n",
       "0            not satisfied many bugs and issues  Negative\n",
       "1    amazing quality and userfriendly interface  Positive\n",
       "2  terrible experience needs major improvements  Negative\n",
       "3         poor performance and not userfriendly  Negative\n",
       "4            not satisfied many bugs and issues  Negative"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/clean_reviews.csv\")\n",
    "\n",
    "df = df[[\"clean_review\", \"sentiment\"]]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2070edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Neutral', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"sentiment_encoded\"] = label_encoder.fit_transform(df[\"sentiment\"])\n",
    "\n",
    "label_encoder.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcecdec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"clean_review\"],\n",
    "    df[\"sentiment_encoded\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"sentiment_encoded\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5de48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 10000\n",
    "MAX_LEN = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq  = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\")\n",
    "X_test_pad  = pad_sequences(X_test_seq,  maxlen=MAX_LEN, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ea3465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1331587 (5.08 MB)\n",
      "Trainable params: 1331587 (5.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(3, activation=\"softmax\")   # 3 sentiment classes\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e01114f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 2s 189ms/step - loss: 1.0889 - accuracy: 0.3969 - val_loss: 1.0854 - val_accuracy: 0.3500\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 1.0792 - accuracy: 0.3750 - val_loss: 1.0769 - val_accuracy: 0.3500\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 1.0631 - accuracy: 0.4344 - val_loss: 1.0778 - val_accuracy: 0.3500\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 1.0634 - accuracy: 0.4094 - val_loss: 1.0815 - val_accuracy: 0.3500\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "874fa2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0685 - accuracy: 0.4000\n",
      "Test Accuracy: 0.4000000059604645\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_pad, y_test)\n",
    "print(\"Test Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3121e38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/lstm_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/lstm_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LSTM model saved successfully\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models/lstm_model\")\n",
    "\n",
    "with open(\"../models/lstm_tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "with open(\"../models/lstm_label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print(\"✅ LSTM model saved successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
